{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TP3 KDE Kernel Density Estimation\n",
    "* obligatory\n",
    "* individual work\n",
    "* The report (.pdf or jupyter notebook)  \n",
    "    - should start with a short introdution\n",
    "    - to explan the problem, \n",
    "    - explan a bit the specific method that you are going to use\n",
    "    - should include a detailed description of your observations, e.g. comments on the forms of the density functions, the classification performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The TP is divided in three parts: \n",
    "* The first part concerns the definition of the appropriate functions for probability density estimation using kernels and the study of the effect of the h parameter on a simple artificial set. \n",
    "* The second concerns the application of the functions written previously on the iris dataset. \n",
    "* The third is to apply the density estimation to a classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import show\n",
    "from itertools import combinations\n",
    "\n",
    "# make figures appear inline\n",
    "%matplotlib inline\n",
    "\n",
    "# notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define training set\n",
    "Let your training set consist of four points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training set\n",
    "c = np.array([[1,1],[1,4],[3,2.5],[4,2.5]])\n",
    "n = c.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define test set\n",
    "Create a regular set of points which cover the plane $[0, 5] \\times [0, 5]$  and stores them in testSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test set\n",
    "min_X, max_X = 0, 5\n",
    "min_Y, max_Y = 0, 5\n",
    "intLength = 30\n",
    "x = np.linspace(min_X, max_X, num=intLength)\n",
    "y = np.linspace(min_Y, max_Y, num=intLength)\n",
    "testSet = np.transpose([np.tile(x, len(y)), np.repeat(y, len(x))])\n",
    "X,Y = np.meshgrid(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testSet\n",
      "[[0.         0.        ]\n",
      " [0.17241379 0.        ]\n",
      " [0.34482759 0.        ]\n",
      " ...\n",
      " [4.65517241 5.        ]\n",
      " [4.82758621 5.        ]\n",
      " [5.         5.        ]]\n",
      "testSet shape:  (900, 2)\n"
     ]
    }
   ],
   "source": [
    "print('testSet')\n",
    "print( testSet)\n",
    "print('testSet shape: ', testSet.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define of the appropriate functions for probability density estimation using kernels \n",
    "\n",
    "Open ```kde.py```, here you can find some examples you might need. you can either complete it or make your own code from scratch.\n",
    "\n",
    "To compute the dencity estimation you can using the univariate version of kernel or the multivariate version of the kernel (use the one that you prefer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (kde.py, line 29)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/Users/Frantzeska/anaconda3/lib/python3.5/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m2910\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-c479bb2a63d5>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from kde import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/Users/Frantzeska/Work/dmml/datamining_unige/2019-20/TP3_KDE/TP3_KDE/kde.py\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    return normalKernelMultiD((X - c) / h, d)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "from kde import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normalKernel1D' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-aada69df50a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnormalKernel1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestSet\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'normalKernel1D' is not defined"
     ]
    }
   ],
   "source": [
    "normalKernel1D(testSet[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalKernelMultiD(testSet[1], c.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multivariate version of Kernel\n",
    "normalKernelMultiD(testSet[1]-c[1],c.shape[1])\n",
    "multiKernel = deltaMultiD(testSet[1],c[1],0.2,c.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# univariate version of Kernel\n",
    "normalKernel1D(testSet[1]-c[1])\n",
    "uniKernel = deltaProd(testSet[1],c[1],0.2,c.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the univariate version of kernel and the multivariate version produce the same results\n",
    "\n",
    "difference = np.linalg.norm(uniKernel - multiKernel)\n",
    "print('Difference was: %f' % (difference, ))\n",
    "if difference < 0.001:\n",
    "    print('Good! The two methods give the same result')\n",
    "else:\n",
    "    print('Uh-oh! The two methods are different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "\n",
    "# smoothing parameters\n",
    "h = np.array([0.3,0.4,0.5])\n",
    "\n",
    "# dimensionality of the test set\n",
    "d = testSet.shape[1] \n",
    "print(\"dimensionality of the test set:\"+str(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1. Plot p(x|ci) for every ci using h : 0.3, 0.4, 0.5 and comment your results. For a specific center (training point) comment how h influences the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot conditional density function\n",
    "for j in range(len(h)):\n",
    "    for i in range(len(c)):\n",
    "        fig=plt.figure()\n",
    "        ax=fig.add_subplot(111,projection='3d')\n",
    "        ax.set_title(\"Kernel Function at point :  c = \"+str(c[i])+ \". h : \"+str(h[j]))\n",
    "        ax.plot_surface(X,Y,densityEstimation().reshape(30,30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex1. Plot p(x)  using h : 0.3, 0.4, 0.5 and comment your results. Discuss the effect ofthe size of h."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot density function \n",
    "for i in range(len(h)):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111, projection='3d')\n",
    "    ax.set_title(\"Density Function p(x), h:\"+str(h[i]))\n",
    "    ax.plot_surface(X,Y,densityEstimation().reshape(30,30))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex2. Iris dataset: Using the functions that you created above (exercise 1) work with the iris dataset.\n",
    "* Plot the class conditional density of each attribute\n",
    "* For a given pair of attributes draw the two dimensional density for each class\n",
    "* Experiment with at least three different values of the h parameter and comment on your findings (in details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris data.\n",
    "\n",
    "from data_utils import load_IRIS\n",
    "\n",
    "\n",
    "\n",
    "data_X, data_y = load_IRIS(test=False)\n",
    "\n",
    "# As a sanity check, we print out the size of the data.\n",
    "print('data shape: ', data_X.shape)\n",
    "print('labels shape: ', data_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful functions than you maybe wont to use (it's uo to you)\n",
    "unique_y = np.unique (data_y)\n",
    "points_by_class = [[x for x, t in zip (data_X, data_y) if t == c] for c in unique_y]\n",
    "points_by_class_array = np.asarray(points_by_class)\n",
    "points_by_class_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ex3. Iris dataset: Naive Bayes\n",
    " Implement the Naive Bayes on iris dataset but now instead of assuming normal distribution estimate the probability distribution from the data using kernel density estimation with h : 0.3, 0.4, 0.5.\n",
    "* Discuss the effect of the h parameter in the accuracy of the algorithm\n",
    "* Compare with the results that you had in TP1 Naive Beyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
